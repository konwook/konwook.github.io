<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" type="image/png" sizes="any" href="/favicon.png" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
		<link href="./_app/immutable/assets/0.7e1c3e9e.css" rel="stylesheet">
		<link href="./_app/immutable/assets/3.ae31a64c.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.e18f710a.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.d20aca82.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/singletons.9e9297a7.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.cc24934a.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.ab0ea39a.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.c59630cf.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/stores.13ad6f8a.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/3.6ee1821f.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Icon.704ad60a.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Seo.46691398.js"><title>Konwoo Kim – Projects</title><!-- HEAD_svelte-1gfocz2_START -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-E6MHV1GQT5"></script>
    <script>window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "G-E6MHV1GQT5");
    </script><!-- HEAD_svelte-1gfocz2_END --><!-- HEAD_svelte-1alr8gw_START --><meta name="description" content="Software and research projects in systems, computer graphics, and machine learning."><meta property="og:title" content="Konwoo Kim – Projects"><meta property="og:description" content="Software and research projects in systems, computer graphics, and machine learning."><meta name="twitter:card" content="summary_large_image"><!-- HEAD_svelte-1alr8gw_END -->
  </head>
  <body>
    <div>




<header class="layout-md flex justify-between items-start" data-sveltekit-noscroll data-sveltekit-preload-code="eager"><h1 class="font-bold text-black text-2xl mb-6"><a href="/">Konwoo Kim</a>
    <span class="page-title svelte-bgdsr9"><span class="text-neutral-400 svelte-bgdsr9">—</span>
        Projects</span></h1>
  <nav class="svelte-bgdsr9"><a href="/projects" class="hover:text-black transition-colors svelte-bgdsr9 text-black">projects
      </a><a href="/resume" class="hover:text-black transition-colors svelte-bgdsr9">resume
      </a></nav>
</header>

<main>

<div class="bg-gray-900 text-neutral-200 dark"><section class="layout-md py-12"><h2 class="heading2 text-white">Table of Contents</h2>
    <ul class="sm:columns-2"><li><a class="link" href="#compiler">C0 Compiler</a>
        </li><li><a class="link" href="#galen">Galen</a>
        </li><li><a class="link" href="#clip">How to Adapt CLIP</a>
        </li><li><a class="link" href="#image_editing">Invert and Factor</a>
        </li><li><a class="link" href="#mticl">Multi-task ICL</a>
        </li><li><a class="link" href="#render">Path Tracer</a>
        </li><li><a class="link" href="#fluid_sim">Position Based Fluids</a>
        </li><li><a class="link" href="#rhythmic">rhythmic.live</a>
        </li></ul></section></div>

<div class="bg-neutral-50 border-b border-neutral-200 py-4"><div class="flex justify-center space-x-6"><button class="svelte-1qrsmpk active"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.8" stroke-linecap="round" stroke-linejoin="round" class="lucide-icon lucide lucide-calendar-days mr-1.5"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line><path d="M8 14h.01"></path><path d="M12 14h.01"></path><path d="M16 14h.01"></path><path d="M8 18h.01"></path><path d="M12 18h.01"></path><path d="M16 18h.01"></path></svg> by Date
    </button>
    </div></div>

<section class="py-10" id="mticl"><div class="mx-auto max-w-[1152px] px-4 sm:px-6">
<h3 class="text-black text-xl font-semibold mb-2"><span class="mr-1">Multi-task ICL</span>
  <small class="whitespace-nowrap text-neutral-500 text-base font-normal">September 2023</small></h3>


<div class="flex flex-wrap mb-1">
  <div class="pill svelte-1d8a62h">Python</div><div class="pill svelte-1d8a62h">Reinforcement Learning</div><div class="pill svelte-1d8a62h">Machine Learning</div><div class="pill svelte-1d8a62h">Research</div></div>


<div class="space-y-4"><div class="grid grid-cols-3 gap-4 md:gap-8 lg:gap-12"><div class="col-span-3 md:col-span-2"><p class="text-lg font-light mb-3">Learning shared safety constraints from multi-task demos.</p>
      <div class="md-output svelte-19wf98v"><!-- HTML_TAG_START --><p>Regardless of the particular task we want them to perform in an environment, there are often shared safety constraints we want our agents to respect. Manually specifying such a constraint can be both time-consuming and error-prone. We show how to learn constraints from expert demonstrations of safe task completion by extending inverse reinforcement learning (IRL) techniques to the space of constraints. Intuitively, we learn constraints that forbid highly rewarding behavior that the expert could have taken but chose not to.</p>
<p>Unfortunately, the constraint learning problem is rather ill-posed and typically leads to overly conservative constraints that forbid all behavior that the expert did not take. We counter this by leveraging diverse demonstrations that naturally occur in multi-task settings to learn a tighter set of constraints. We validate our method with simulation experiments on high-dimensional continuous control tasks.</p>
<p><strong>Links: <a rel="external" href="https://arxiv.org/abs/2309.00711" class="link">Paper</a>,
<a rel="external" href="https://gokul.dev/icl/" class="link">Website</a>,
<a rel="external" href="https://github.com/konwook/mticl" class="link">Github</a></strong></p>
<!-- HTML_TAG_END -->
</div></div>
    <div class="col-span-3 md:col-span-1"><a rel="external" href="/_app/immutable/assets/icl_ffig.4260e361.svg"><img src="/_app/immutable/assets/icl_ffig.4260e361.svg" alt="Multi-task ICL preview image"></a></div></div>

  
</div></div>
  </section><section class="py-10" id="fluid_sim"><div class="mx-auto max-w-[1152px] px-4 sm:px-6">
<h3 class="text-black text-xl font-semibold mb-2"><span class="mr-1">Position Based Fluids</span>
  <small class="whitespace-nowrap text-neutral-500 text-base font-normal">December 2022</small></h3>


<div class="flex flex-wrap mb-1">
  <div class="pill svelte-1d8a62h">C++</div><div class="pill svelte-1d8a62h">CUDA</div><div class="pill svelte-1d8a62h">Rendering</div><div class="pill svelte-1d8a62h">OpenGL</div></div>


<div class="space-y-4"><div class="grid grid-cols-3 gap-4 md:gap-8 lg:gap-12"><div class="col-span-3 md:col-span-2"><p class="text-lg font-light mb-3">Parallel fluid simulation in CUDA.</p>
      <div class="md-output svelte-19wf98v"><!-- HTML_TAG_START --><p>This is a sequential and parallel <a rel="external" href="https://dl.acm.org/doi/10.1145/2461912.2461984" class="link">position-based fluid simulator</a>
implemented in C++ and CUDA with a custom renderer in OpenGL. The parallel simulator supports data parallelism,
efficient neighbor computation using parallel counting sort, and multi-threaded rendering. It achieves
speedups of up to 30x over the sequential simulator and supports real-time simulation and rendering up to 100,000 particles.</p>
<p><strong>Links: <a rel="external" href="https://github.com/ldcWV/FluidSimulation" class="link">GitHub</a>,
<a rel="external" href="assets/pdf/fluid_sim.pdf" class="link">Writeup</a></strong></p>
<!-- HTML_TAG_END -->
</div></div>
    <div class="col-span-3 md:col-span-1"><a rel="external" href="/_app/immutable/assets/fluid_sim.ddfc3ee2.png"><img src="/_app/immutable/assets/fluid_sim.ddfc3ee2.png" alt="Position Based Fluids preview image"></a></div></div>

  
</div></div>
  </section><section class="py-10" id="galen"><div class="mx-auto max-w-[1152px] px-4 sm:px-6">
<h3 class="text-black text-xl font-semibold mb-2"><span class="mr-1">Galen</span>
  <small class="whitespace-nowrap text-neutral-500 text-base font-normal">October 2022</small></h3>


<div class="flex flex-wrap mb-1">
  <div class="pill svelte-1d8a62h">Python</div><div class="pill svelte-1d8a62h">OCaml</div><div class="pill svelte-1d8a62h">Swift</div><div class="pill svelte-1d8a62h">JavaScript</div><div class="pill svelte-1d8a62h">Machine Learning</div></div>


<div class="space-y-4"><div class="grid grid-cols-3 gap-4 md:gap-8 lg:gap-12"><div class="col-span-3 md:col-span-2"><p class="text-lg font-light mb-3">Real-time surgical feedback with interactive AI.</p>
      <div class="md-output svelte-19wf98v"><!-- HTML_TAG_START --><p>Galen is an iOS app and platform which combines state-of-the-art speech to text recognition, few-shot text parsing, and medical data analysis to prevent surgical errors.</p>
<p>Galen aims to keep track of surgical actions and verify that they are safe. To do so, it analyzes surgical audio using <a rel="external" href="https://openai.com/blog/whisper/" class="link">Whisper</a> and GPT-3 and certifies that each surgical operation is safe with respect to patient information and an existing <a rel="external" href="https://snap.stanford.edu/biodata/datasets/10002/10002-ChG-Miner.html" class="link">database of drug interactions</a>.</p>
<p>This project received Best Distributed Systems Hack and placed 2nd in the iOS Development Challenge and YC Startup Pitch at <a rel="external" href="https://dayof.hackmit.org/#home" class="link">HackMIT 2022</a>.</p>
<p><strong>Links: <a rel="external" href="https://github.com/orgs/GalenAI/repositories" class="link">Github</a></strong></p>
<!-- HTML_TAG_END -->
</div></div>
    <div class="col-span-3 md:col-span-1"><a rel="external" href="/_app/immutable/assets/galen.59914991.png"><img src="/_app/immutable/assets/galen.59914991.png" alt="Galen preview image"></a></div></div>

  
</div></div>
  </section><section class="py-10" id="render"><div class="mx-auto max-w-[1152px] px-4 sm:px-6">
<h3 class="text-black text-xl font-semibold mb-2"><span class="mr-1">Path Tracer</span>
  <small class="whitespace-nowrap text-neutral-500 text-base font-normal">May 2022</small></h3>


<div class="flex flex-wrap mb-1">
  <div class="pill svelte-1d8a62h">C++</div><div class="pill svelte-1d8a62h">Rendering</div></div>


<div class="space-y-4"><div class="grid grid-cols-3 gap-4 md:gap-8 lg:gap-12"><div class="col-span-3 md:col-span-2"><p class="text-lg font-light mb-3">Physics-based path tracer in C++.</p>
      <div class="md-output svelte-19wf98v"><!-- HTML_TAG_START --><p>This is a physics-based path tracer implemented in C++. It features path tracing with multiple importance sampling,
quasi-Monte Carlo sampling, texture mapping, various microfacet models and integrators, and volumetric
rendering.</p>
<p>Several methods for rendering heterogenous media are implemented including ratio and
delta tracking, analog decomposition tracking, spectral tracking, and spectral multiple importance sampling.</p>
<p><strong>Links: <a rel="external" href="assets/pdf/render.pdf" class="link">Writeup</a></strong></p>
<!-- HTML_TAG_END -->
</div></div>
    <div class="col-span-3 md:col-span-1"><a rel="external" href="/_app/immutable/assets/render.1f159690.png"><img src="/_app/immutable/assets/render.1f159690.png" alt="Path Tracer preview image"></a></div></div>

  
</div></div>
  </section><section class="py-10" id="clip"><div class="mx-auto max-w-[1152px] px-4 sm:px-6">
<h3 class="text-black text-xl font-semibold mb-2"><span class="mr-1">How to Adapt CLIP</span>
  <small class="whitespace-nowrap text-neutral-500 text-base font-normal">December 2021</small></h3>


<div class="flex flex-wrap mb-1">
  <div class="pill svelte-1d8a62h">Python</div><div class="pill svelte-1d8a62h">Machine Learning</div><div class="pill svelte-1d8a62h">Research</div></div>


<div class="space-y-4"><div class="grid grid-cols-3 gap-4 md:gap-8 lg:gap-12"><div class="col-span-3 md:col-span-2"><p class="text-lg font-light mb-3">Robust fine-tuning of large-scale pretrained models.</p>
      <div class="md-output svelte-19wf98v"><!-- HTML_TAG_START --><p>Pre-training large-scale vision and language models (e.g. <a rel="external" href="https://openai.com/blog/clip/" class="link">CLIP</a>) has shown promising results in representation and transfer learning. This research project (advised by Prof. Deepak Pathak, Dr. Igor Mordatch, and Dr. Michael Laskin) investigates the question of how to efficiently adapt these models to out-of-distribution downstream tasks. We analyze several fine-tuning methods for a diverse set of image classification tasks across two spectra — the amount and similarity of the downstream and pretraining data.</p>
<p>Our primary contribution is to show that just tuning LayerNorm paramters is a surprisingly effective baseline across the board. We further demonstrate a simple strategy for combining LayerNorm-tuning with general fine-tuning methods to improve their performance and benchmark them on few-shot adaptation and distribution shift tasks. Finally, we provide an empirical analysis and recommend general recipes for efficient transfer learning of CLIP-like models.</p>
<p><strong>Links: <a rel="external" href="assets/pdf/clip.pdf" class="link">Paper</a>,
<a rel="external" href="assets/pdf/clip_poster.pdf" class="link">Poster</a></strong></p>
<!-- HTML_TAG_END -->
</div></div>
    <div class="col-span-3 md:col-span-1"><a rel="external" href="/_app/immutable/assets/clip.d72bb3c4.png"><img src="/_app/immutable/assets/clip.d72bb3c4.png" alt="How to Adapt CLIP preview image"></a></div></div>

  
</div></div>
  </section><section class="py-10" id="compiler"><div class="mx-auto max-w-[1152px] px-4 sm:px-6">
<h3 class="text-black text-xl font-semibold mb-2"><span class="mr-1">C0 Compiler</span>
  <small class="whitespace-nowrap text-neutral-500 text-base font-normal">December 2021</small></h3>


<div class="flex flex-wrap mb-1">
  <div class="pill svelte-1d8a62h">Rust</div><div class="pill svelte-1d8a62h">Systems</div></div>


<div class="space-y-4"><div class="grid grid-cols-3 gap-4 md:gap-8 lg:gap-12"><div class="col-span-3 md:col-span-2"><p class="text-lg font-light mb-3">C0 to x86 compiler.</p>
      <div class="md-output svelte-19wf98v"><!-- HTML_TAG_START --><p>This is a compiler implemented in Rust for <a rel="external" href="https://bitbucket.org/c0-lang/docs/wiki/Home" class="link">C0</a>, a safe subset of C, to x86 assembly. It features
lexing and parsing, type-checking, code generation and emission, register allocation and coalescing, and several peephole optimizations.</p>
<p>Additionally, it supports a threading runtime system inspired by <a rel="external" href="https://www.opencilk.org/" class="link">Cilk</a> and general task parallelism with spawn/sync calls
and automated work stealing.</p>
<p><strong>Links: <a rel="external" href="assets/pdf/compiler.pdf" class="link">Writeup</a></strong></p>
<!-- HTML_TAG_END -->
</div></div>
    <div class="col-span-3 md:col-span-1"><a rel="external" href="/_app/immutable/assets/compiler.3cbd77e1.png"><img src="/_app/immutable/assets/compiler.3cbd77e1.png" alt="C0 Compiler preview image"></a></div></div>

  
</div></div>
  </section><section class="py-10" id="image_editing"><div class="mx-auto max-w-[1152px] px-4 sm:px-6">
<h3 class="text-black text-xl font-semibold mb-2"><span class="mr-1">Invert and Factor</span>
  <small class="whitespace-nowrap text-neutral-500 text-base font-normal">May 2021</small></h3>


<div class="flex flex-wrap mb-1">
  <div class="pill svelte-1d8a62h">Python</div><div class="pill svelte-1d8a62h">Machine Learning</div><div class="pill svelte-1d8a62h">Image Synthesis</div></div>


<div class="space-y-4"><div class="grid grid-cols-3 gap-4 md:gap-8 lg:gap-12"><div class="col-span-3 md:col-span-2"><p class="text-lg font-light mb-3">Unsupervised, interpretable image editing.</p>
      <div class="md-output svelte-19wf98v"><!-- HTML_TAG_START --><p>Invert and Factor is an image editing web interface combining <a rel="external" href="https://arxiv.org/pdf/2102.02766.pdf" class="link">GAN inversion</a> with <a rel="external" href="https://arxiv.org/pdf/2007.06600.pdf" class="link">semantic factorization</a>. Users can upload an image of a face to the interface and modify it by manipulating sliders which correspond to semantic attributes.</p>
<p>Semantic factorization provides semantically meaningful directions in the latent space of a generative model in a fast and unsupervised manner. Combining this with a pretrained inversion model and <a rel="external" href="https://arxiv.org/pdf/1912.04958.pdf" class="link">StyleGan2 generator</a> allows for an uploaded image to be inverted, factorized, manipulated, and re-generated in real-time.</p>
<p><strong>Links: <a rel="external" href="https://github.com/konwook/Invert-and-Factor" class="link">GitHub</a>,
<a rel="external" href="https://www.andrew.cmu.edu/course/16-726/projects/konwook/project/" class="link">Website</a></strong></p>
<!-- HTML_TAG_END -->
</div></div>
    <div class="col-span-3 md:col-span-1"><a rel="external" href="/_app/immutable/assets/image_editing.019bba0f.png"><img src="/_app/immutable/assets/image_editing.019bba0f.png" alt="Invert and Factor preview image"></a></div></div>

  
</div></div>
  </section><section class="py-10" id="rhythmic"><div class="mx-auto max-w-[1152px] px-4 sm:px-6">
<h3 class="text-black text-xl font-semibold mb-2"><span class="mr-1">rhythmic.live</span>
  <small class="whitespace-nowrap text-neutral-500 text-base font-normal">September 2020</small></h3>


<div class="flex flex-wrap mb-1">
  <div class="pill svelte-1d8a62h">Python</div><div class="pill svelte-1d8a62h">JavaScript</div></div>


<div class="space-y-4"><div class="grid grid-cols-3 gap-4 md:gap-8 lg:gap-12"><div class="col-span-3 md:col-span-2"><p class="text-lg font-light mb-3">Collaborative music making.</p>
      <div class="md-output svelte-19wf98v"><!-- HTML_TAG_START --><p>rhythmic.live is a collaborative music making platform providing audio synchronization, interactive and browser-compatible sheet music,
and informative analytics.</p>
<p>Musicions can join a recording session from the web app which a conductor manages. When a session begins,
separate recording sessions are started and the audio streams are reconstructed in sync and stored. After each recording, the conductor
can browse recent recordings, listem to them, and receive algorithmic feedback about tone, timbre, and rhythm.</p>
<p>This project won the NASDAQ Music Challenge at <a rel="external" href="https://archive.hackmit.org/2020/" class="link">HackMIT 2020</a>.</p>
<p><strong>Links: <a rel="external" href="https://github.com/rhythmic-live" class="link">Github</a></strong></p>
<!-- HTML_TAG_END -->
</div></div>
    <div class="col-span-3 md:col-span-1"><a rel="external" href="/_app/immutable/assets/rhythmic.5b3294bc.png"><img src="/_app/immutable/assets/rhythmic.5b3294bc.png" alt="rhythmic.live preview image"></a></div></div>

  
</div></div>
  </section></main>

<footer class="layout-md mt-20 text-lg flex flex-col"><div class="row svelte-1wz9633"><span class="svelte-1wz9633">GitHub</span>
    <hr class="svelte-1wz9633">
    <a class="link svelte-1wz9633" href="https://github.com/konwook">@konwook</a></div>
  <div class="row svelte-1wz9633"><span class="svelte-1wz9633">Email</span>
    <hr class="svelte-1wz9633">
    <a class="link svelte-1wz9633" href="mailto:konwoo.kim@gmail.com">konwoo.kim@gmail.com</a></div>
  <div class="row svelte-1wz9633"><credit class="svelte-1wz9633">Design by <a class="link" href="https://ekzhang.com">Eric Zhang</a>.
    </credit></div>
</footer>


			
			<script>
				{
					__sveltekit_xowrht = {
						base: new URL(".", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("./_app/immutable/entry/start.e18f710a.js"),
						import("./_app/immutable/entry/app.cc24934a.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 3],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
  </body>
</html>
